# src/tools/train_3month.py
"""
3ê°œì›” í•™ìŠµ ë° 2ì£¼ ì˜ˆì¸¡ í†µí•© ìŠ¤í¬ë¦½íŠ¸
ì‚¼ì„±ì „ì(005930)ì™€ SKí•˜ì´ë‹‰ìŠ¤(000660)ë¥¼ ëª¨ë‘ ì²˜ë¦¬
"""
import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from datetime import datetime, timedelta
from src.db.connection import get_db_cursor
from src.learner.lasso import LassoLearner
from src.utils import calendar_helper
import json

# 3ê°œì›” í•™ìŠµ (Sep 19 ~ Dec 19)
TRAIN_END = datetime(2025, 12, 19)
TRAIN_START = TRAIN_END - timedelta(days=90)

# ì˜ˆì¸¡ ê¸°ê°„ (Dec 22 ~ Jan 10, 3ì£¼)
PRED_START = datetime(2025, 12, 22)
PRED_END = datetime(2026, 1, 10)

STOCKS = [
    {"code": "005930", "name": "ì‚¼ì„±ì „ì", "version": "phase14_3m_samsung"},
    {"code": "000660", "name": "SKí•˜ì´ë‹‰ìŠ¤", "version": "phase14_3m_skhynix"},
]

def train_stock(stock_code, stock_name, version):
    """Train a stock with 3 months of data"""
    print(f"\n{'='*60}")
    print(f"  {stock_name} ({stock_code}) - 3ê°œì›” í•™ìŠµ")
    print(f"  í•™ìŠµ ê¸°ê°„: {TRAIN_START.date()} ~ {TRAIN_END.date()}")
    print(f"{'='*60}")
    
    # 1. Check news availability
    with get_db_cursor() as cur:
        cur.execute("""
            SELECT COUNT(*) as cnt
            FROM tb_news_content c
            JOIN tb_news_mapping m ON c.url_hash = m.url_hash
            WHERE m.stock_code = %s AND c.published_at BETWEEN %s AND %s
        """, (stock_code, TRAIN_START, TRAIN_END))
        news_count = cur.fetchone()['cnt']
        print(f"[âœ“] ë‰´ìŠ¤ ë°ì´í„°: {news_count}ê±´")
    
    # 2. Train model
    print(f"[1/3] ëª¨ë¸ í•™ìŠµ ì¤‘...")
    learner = LassoLearner()
    learner.run_training(
        stock_code=stock_code,
        start_date=TRAIN_START.strftime('%Y-%m-%d'),
        end_date=TRAIN_END.strftime('%Y-%m-%d'),
        version=version,
        source='Main',
        is_active=True
    )
    print(f"[âœ“] í•™ìŠµ ì™„ë£Œ: {version}")
    
    # 3. Generate predictions
    print(f"[2/3] ì˜ˆì¸¡ ìƒì„± ì¤‘...")
    generate_predictions(stock_code, version)
    
    # 4. Create verification job
    print(f"[3/3] ê²€ì¦ ë³´ê³ ì„œ ìƒì„± ì¤‘...")
    v_job_id = create_verification_job(stock_code, version)
    
    print(f"\n[âœ…] {stock_name} ì™„ë£Œ!")
    print(f"    ì†Œë¹„ì ëŒ€ì‹œë³´ë“œ: http://localhost:8081/analytics/outlook?stock_code={stock_code}")
    print(f"    ì „ë¬¸ê°€ ëŒ€ì‹œë³´ë“œ: http://localhost:8081/analytics/expert?stock_code={stock_code}&v_job_id={v_job_id}")
    
    return v_job_id

def generate_predictions(stock_code, version):
    """Generate predictions using the trained model"""
    with get_db_cursor() as cur:
        # Load sentiment dictionary
        cur.execute("""
            SELECT word, beta FROM tb_sentiment_dict
            WHERE stock_code = %s AND version = %s
        """, (stock_code, version))
        sentiment_dict = {row['word']: float(row['beta']) for row in cur.fetchall()}
        
        if not sentiment_dict:
            cur.execute("""
                SELECT word, beta FROM tb_sentiment_dict
                WHERE stock_code = %s ORDER BY updated_at DESC LIMIT 500
            """, (stock_code,))
            sentiment_dict = {row['word']: float(row['beta']) for row in cur.fetchall()}
        
        print(f"    ê°ì„± ë‹¨ì–´ ë¡œë“œ: {len(sentiment_dict)}ê°œ")
        
        # Load news from training window
        cur.execute("""
            SELECT c.content, c.published_at
            FROM tb_news_content c
            JOIN tb_news_mapping m ON c.url_hash = m.url_hash
            WHERE m.stock_code = %s AND c.published_at BETWEEN %s AND %s
            ORDER BY c.published_at DESC
        """, (stock_code, TRAIN_START, TRAIN_END))
        news_items = cur.fetchall()
        
        # Generate for each trading day
        current = PRED_START
        predictions_made = 0
        
        while current <= PRED_END:
            date_str = current.strftime('%Y-%m-%d')
            
            if calendar_helper.is_trading_day(date_str):
                total_score = 0.0
                news_count = 0
                
                for news in news_items:
                    content = news['content'] or ''
                    pub_date = news['published_at'].date() if news['published_at'] else TRAIN_END.date()
                    days_ago = (current.date() - pub_date).days
                    
                    decay = 0.95 ** days_ago if days_ago > 0 else 1.0
                    words = content.lower().split()
                    article_score = sum(sentiment_dict.get(w, 0) for w in words)
                    
                    if article_score != 0:
                        total_score += article_score * decay
                        news_count += 1
                
                if news_count > 0:
                    final_score = total_score / (news_count ** 0.5)
                else:
                    final_score = 0
                
                # Status determination
                if final_score > 2.0:
                    status, expected_alpha = "Super Buy", 0.15
                elif final_score > 0.5:
                    status, expected_alpha = "Cautious Buy", 0.05
                elif final_score < -2.0:
                    status, expected_alpha = "Super Sell", -0.15
                elif final_score < -0.5:
                    status, expected_alpha = "Cautious Sell", -0.05
                else:
                    status, expected_alpha = "Neutral", 0.0
                
                # Delete & Insert
                cur.execute("DELETE FROM tb_predictions WHERE stock_code = %s AND prediction_date = %s", 
                           (stock_code, date_str))
                cur.execute("""
                    INSERT INTO tb_predictions (stock_code, prediction_date, sentiment_score, expected_alpha, status, intensity, top_keywords)
                    VALUES (%s, %s, %s, %s, %s, %s, %s)
                """, (
                    stock_code, date_str, final_score, expected_alpha, status,
                    min(abs(final_score) / 5.0, 1.0),
                    json.dumps({"version": version, "news_count": news_count})
                ))
                
                predictions_made += 1
                print(f"    {date_str}: {status} (score: {final_score:.2f})")
            
            current += timedelta(days=1)
        
        print(f"    ì´ {predictions_made}ê°œ ì˜ˆì¸¡ ìƒì„±")

def create_verification_job(stock_code, version):
    """Create a verification job entry"""
    with get_db_cursor() as cur:
        cur.execute("""
            INSERT INTO tb_verification_jobs (stock_code, v_type, params, status, started_at, completed_at)
            VALUES (%s, 'MANUAL_3M_TRAIN', %s, 'completed', %s, CURRENT_TIMESTAMP)
            RETURNING v_job_id
        """, (
            stock_code,
            json.dumps({
                "train_start": TRAIN_START.strftime('%Y-%m-%d'),
                "train_end": TRAIN_END.strftime('%Y-%m-%d'),
                "pred_start": PRED_START.strftime('%Y-%m-%d'),
                "pred_end": PRED_END.strftime('%Y-%m-%d'),
                "version": version,
                "train_days": 90
            }),
            datetime.now() - timedelta(minutes=5)
        ))
        v_job_id = cur.fetchone()['v_job_id']
        
        # Add verification results from predictions
        cur.execute("""
            SELECT prediction_date, sentiment_score, expected_alpha, status
            FROM tb_predictions
            WHERE stock_code = %s AND prediction_date BETWEEN %s AND %s
            ORDER BY prediction_date
        """, (stock_code, PRED_START, PRED_END))
        
        predictions = cur.fetchall()
        for pred in predictions:
            cur.execute("""
                INSERT INTO tb_verification_results (v_job_id, target_date, predicted_score, actual_alpha, is_correct, used_version)
                VALUES (%s, %s, %s, NULL, NULL, %s)
            """, (v_job_id, pred['prediction_date'], float(pred['sentiment_score'] or 0), version))
        
        print(f"    ê²€ì¦ Job #{v_job_id} ìƒì„± ({len(predictions)}ê°œ ì—”íŠ¸ë¦¬)")
        return v_job_id

def main():
    print("\n" + "="*70)
    print("  N-SentiTrader 3ê°œì›” í•™ìŠµ ë° ë³´ê³ ì„œ ìƒì„±")
    print("  ëŒ€ìƒ: ì‚¼ì„±ì „ì(005930), SKí•˜ì´ë‹‰ìŠ¤(000660)")
    print(f"  í•™ìŠµ ê¸°ê°„: {TRAIN_START.date()} ~ {TRAIN_END.date()} (90ì¼)")
    print(f"  ì˜ˆì¸¡ ê¸°ê°„: {PRED_START.date()} ~ {PRED_END.date()}")
    print("="*70)
    
    results = []
    for stock in STOCKS:
        v_job_id = train_stock(stock["code"], stock["name"], stock["version"])
        results.append({"stock": stock, "v_job_id": v_job_id})
    
    print("\n" + "="*70)
    print("  ğŸ‰ ì „ì²´ ì‘ì—… ì™„ë£Œ!")
    print("="*70)
    for r in results:
        print(f"\n  {r['stock']['name']} ({r['stock']['code']}):")
        print(f"    - ëª¨ë¸ ë²„ì „: {r['stock']['version']}")
        print(f"    - ê²€ì¦ Job: #{r['v_job_id']}")
        print(f"    - ì†Œë¹„ì: http://localhost:8081/analytics/outlook?stock_code={r['stock']['code']}")
        print(f"    - ì „ë¬¸ê°€: http://localhost:8081/analytics/expert?stock_code={r['stock']['code']}&v_job_id={r['v_job_id']}")

if __name__ == "__main__":
    main()
